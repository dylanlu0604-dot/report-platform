import json
import os
import importlib
import pkgutil
import scrapers  # å¼•å…¥æ•´å€‹ scrapers è³‡æ–™å¤¾

def main():
    print(f"\n{'='*60}")
    print("é–‹å§‹åŸ·è¡Œç¨ç«‹æ¨¡çµ„åŒ–çˆ¬èŸ² (è‡ªå‹•åµæ¸¬æ¨¡å¼)...")
    print(f"{'='*60}\n")
    
    all_reports = []
    
    # ğŸŒŸ é­”æ³•åœ¨é€™è£¡ï¼šè‡ªå‹•æƒæ scrapers è³‡æ–™å¤¾ä¸‹çš„æ‰€æœ‰ .py æª”æ¡ˆ
    for _, module_name, _ in pkgutil.iter_modules(scrapers.__path__):
        
        # æ’é™¤ utils.py (å› ç‚ºå®ƒåªæ˜¯å·¥å…·ç®±ï¼Œä¸æ˜¯çˆ¬èŸ²)
        if module_name == "utils":
            continue
            
        try:
            # å‹•æ…‹è¼‰å…¥æ¨¡çµ„ (ç­‰åŒæ–¼ import scrapers.xxx)
            module = importlib.import_module(f"scrapers.{module_name}")
            
            # ç¢ºä¿é€™å€‹æª”æ¡ˆè£¡é¢æœ‰å¯« scrape() é€™å€‹å‡½æ•¸ï¼Œæ‰å«å®ƒå·¥ä½œ
            if hasattr(module, "scrape"):
                results = module.scrape()
                if results:
                    all_reports.extend(results)
            else:
                print(f"âš ï¸ ç•¥é {module_name}.py (æ‰¾ä¸åˆ° scrape å‡½æ•¸)")
                
        except Exception as e:
            print(f"âŒ è¼‰å…¥æˆ–åŸ·è¡Œ {module_name} å¤±æ•—: {e}")

    if not all_reports:
        print("\nâŒ æœªæŠ“åˆ°ä»»ä½•è³‡æ–™")
        return

    # å»é™¤é‡è¤‡å ±å‘Šï¼ˆåŸºæ–¼ Linkï¼‰
    seen_links = set()
    unique_reports = []
    for report in all_reports:
        if report["Link"] not in seen_links:
            seen_links.add(report["Link"])
            unique_reports.append(report)
            
    print(f"\n{'='*60}")
    print(f"ç¸½å…±æ‰¾åˆ° {len(unique_reports)} ç­†å ±å‘Šï¼ˆå·²å»é‡ï¼‰")
    
    # å»ºç«‹ data è³‡æ–™å¤¾ä¸¦å„²å­˜ç‚º JSON
    os.makedirs('data', exist_ok=True)
    with open('data/reports.json', 'w', encoding='utf-8') as f:
        json.dump(unique_reports, f, ensure_ascii=False, indent=2)
        
    print(f"âœ… æˆåŠŸå°‡ {len(unique_reports)} ç­†è³‡æ–™å„²å­˜è‡³ data/reports.json")
    print(f"{'='*60}")

if __name__ == "__main__":
    main()
